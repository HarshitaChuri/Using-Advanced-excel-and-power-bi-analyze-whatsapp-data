# -*- coding: utf-8 -*-
"""Algorithms_ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1An96pbisAnzFZ67wJRNxFEvesWQM347A
"""

from google.colab import drive
drive.mount('/content/drive')

"""# Linear Regression"""

# Step 1: Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error
import numpy as np
import matplotlib.pyplot as plt

# Step 2: Load your dataset
df = pd.read_csv("/content/drive/MyDrive/DATASCIENCE/Salary_Data.csv")

df.head()

df.info()

# Step 3: Normalize the data
# Using MinMaxScaler
scaler = MinMaxScaler()
df[['YearsExperience', 'Salary']] = scaler.fit_transform(df[['YearsExperience', 'Salary']])

df.head()

# Step 4: Split the data into features (X) and target (y)
X = df[['YearsExperience']]
y = df['Salary']

# Step 5: Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train the model
model = LinearRegression()
model.fit(X_train, y_train)

# Step 7: Evaluate the model
y_pred = model.predict(X_test)

# Calculate performance metrics
mse = mean_squared_error(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mse)

print(f'Mean Squared Error: {mse}')
print(f'Mean Absolute Error: {mae}')
print(f'Root Mean Squared Error: {rmse}')

"""Mean Squared Error: 0.006952407238200638
Mean Absolute Error: 0.07425530156812835
Root Mean Squared Error: 0.08338109640800269
"""

#Print the coefficients
print(f'Coefficients: {model.coef_}')
print(f'Intercept: {model.intercept_}')

# Step 8: Visualize the regression line
# Plotting the original data points
plt.scatter(X, y, color='Green', label='Data points')

# Plotting the regression line
plt.plot(X, model.predict(X), color='orange', linewidth=2, label='Regression line')

# Adding labels and title
plt.xlabel('Years of Experience')
plt.ylabel('Salary')
plt.title('Linear Regression: Salary vs Years of Experience')

# Adding legend
plt.legend()

# Displaying the plot
plt.show()

"""# Logistic regression"""

# Step 1: Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns

#2 data is already loaded above

# Step 2: Convert Salary to Binary Class
# Here, we assume a threshold to create a binary target variable
threshold = df['Salary'].median()
df['SalaryClass'] = (df['Salary'] > threshold).astype(int)

print(df)

# Step 3: Normalize the data
# Using MinMaxScaler
scaler = MinMaxScaler()
df[['YearsExperience']] = scaler.fit_transform(df[['YearsExperience']])

# Step 4: Split the data into features (X) and target (y)
X = df[['YearsExperience']]
y = df['SalaryClass']

# Step 5: Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 6: Train the logistic regression model
model = LogisticRegression()
model.fit(X_train, y_train)

# Step 7: Evaluate the model
y_pred = model.predict(X_test)

# Calculate performance metrics
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)


print(f'Accuracy: {accuracy}')
print('Confusion Matrix:')
print(conf_matrix)
print('Classification Report:')
print(class_report)

#Plot the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Low', 'High'], yticklabels=['Low', 'High'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Visualize the decision boundary

plt.figure(figsize=(10, 6))

# Plotting the data points
sns.scatterplot(x='YearsExperience', y='SalaryClass', data=df, hue='SalaryClass', palette='coolwarm', s=100)

# Plotting the decision boundary
x_values = np.linspace(X['YearsExperience'].min(), X['YearsExperience'].max(), 200)
y_values = -(model.intercept_ + model.coef_[0] * x_values) / model.coef_[0][0]
plt.plot(x_values, y_values, label='Decision Boundary', color='black')

# Adding labels and title
plt.xlabel('Years of Experience')
plt.ylabel('Salary Class (0: Low, 1: High)')
plt.title('Logistic Regression: Salary Classification')

# Adding legend
plt.legend()

# Displaying the plot
plt.show()